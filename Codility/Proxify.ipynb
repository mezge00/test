{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afad9c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1007/s00431-007-0495-y</td>\n",
       "      <td>2008-03-09</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>The present study comprised 29 adolescents and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1345/aph.1K303</td>\n",
       "      <td>2008-02-05</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>Objective: To discuss new therapeutic options ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1586/17474108.3.1.33</td>\n",
       "      <td>2008-01-12</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>A large international conference was held in L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.colsurfa.2007.10.012</td>\n",
       "      <td>2008-03-20</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>The circular patterns of calcium oxalate (CaOx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1111/j.1440-1797.2007.00859.x</td>\n",
       "      <td>2008-04-07</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>Aim: Kidney transplant outcomes have improved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.1021/ja074161f</td>\n",
       "      <td>2008-02-13</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>Au nanoparticles fully coated with Ï‰-ferrocen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.1111/j.1526-4610.1995.hed3505273.x</td>\n",
       "      <td>2008-02-23</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>Headache is a common symptom that constitutes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     doi publication_date  \\\n",
       "0              10.1007/s00431-007-0495-y       2008-03-09   \n",
       "1                      10.1345/aph.1K303       2008-02-05   \n",
       "2                10.1586/17474108.3.1.33       2008-01-12   \n",
       "3         10.1016/j.colsurfa.2007.10.012       2008-03-20   \n",
       "4       10.1111/j.1440-1797.2007.00859.x       2008-04-07   \n",
       "5                      10.1021/ja074161f       2008-02-13   \n",
       "6  10.1111/j.1526-4610.1995.hed3505273.x       2008-02-23   \n",
       "\n",
       "                                               title  \\\n",
       "0  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "1  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "2  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "3  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "4  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "5  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "6  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "\n",
       "                                            abstract  \n",
       "0  The present study comprised 29 adolescents and...  \n",
       "1  Objective: To discuss new therapeutic options ...  \n",
       "2  A large international conference was held in L...  \n",
       "3  The circular patterns of calcium oxalate (CaOx...  \n",
       "4  Aim: Kidney transplant outcomes have improved ...  \n",
       "5  Au nanoparticles fully coated with Ï‰-ferrocen...  \n",
       "6  Headache is a common symptom that constitutes ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "def structure_data():\n",
    "    xml_file_path = 'studies.xml'\n",
    "\n",
    "    with open(xml_file_path, 'r') as f:\n",
    "        data = f.read()\n",
    "    studies_dict = xmltodict.parse(data)\n",
    "\n",
    "    # Initialize lists to store extracted data\n",
    "    dois = []\n",
    "    publication_dates = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "\n",
    "    # Identify the key name for studies\n",
    "    studies_key = next(iter(studies_dict.keys()))\n",
    "\n",
    "    # Iterate through each study item\n",
    "    for study in studies_dict[studies_key]['item']:\n",
    "        # Extracting DOI from nested structure\n",
    "        doi = study.get('bibrecord', {}).get('item-info', {}).get('itemidlist', {}).get('ce:doi', '')\n",
    "\n",
    "        # Extracting Publication Date and converting to YYYY-MM-DD format\n",
    "        publication_date_str = study.get('bibrecord', {}).get('head',{}).get('source',{}).get('publicationdate', {})\n",
    "        year = publication_date_str.get('year', '')\n",
    "        month = publication_date_str.get('month', '')\n",
    "        day = publication_date_str.get('day', '')\n",
    "        publication_date = pd.to_datetime(f'{year}-{month.zfill(2)}-{day.zfill(2)}', errors='coerce')\n",
    "\n",
    "\n",
    "        # Extracting Title\n",
    "        title = study.get('bibrecord', {}).get('head',{}).get('citation-title', {}).get('titletext', '')\n",
    "\n",
    "        # Extracting Abstract\n",
    "        abstract = study.get('bibrecord', {}).get('head',{}).get('abstracts',{}).get('abstract',{}).get('ce:para', '')\n",
    "\n",
    "        # Append extracted data to respective lists\n",
    "        dois.append(doi)\n",
    "        publication_dates.append(publication_date)\n",
    "        titles.append(title)\n",
    "        abstracts.append(abstract)\n",
    "\n",
    "    # Create a DataFrame from the lists\n",
    "    df = pd.DataFrame({\n",
    "        'doi': dois,\n",
    "        'publication_date': publication_dates,\n",
    "        'title': titles,\n",
    "        'abstract': abstracts\n",
    "    })\n",
    "\n",
    "    # Convert publication_date column to datetime64 dtype\n",
    "    df['publication_date'] = pd.to_datetime(df['publication_date'])\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "output = structure_data()\n",
    "output.head(50)\n",
    "\n",
    "# Run tests again\n",
    "# ...\n",
    "\n",
    "# Continue with the rest of the tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05474340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['@xsi:schemaLocation', '@xmlns:xsi', '@xmlns:ait', '@xmlns:ce', '@xmlns', 'item'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studies_dict[studies_key].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4e796c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def structure_dataa():\n",
    "file_path='studies.xml'\n",
    "with open(file_path,'r') as file:\n",
    "    data=file.read()\n",
    "studies_dict=xmltodict.parse(data)\n",
    "studies_key = next(iter(studies_dict.keys()))\n",
    "bibdataset=studies_dict[studies_key].get('bibdataset',{})\n",
    "\n",
    "\n",
    "def structured_datta():\n",
    "    file_path='studies.xml'\n",
    "    with open(file_path,'r') as file:\n",
    "        data=file.read()\n",
    "        \n",
    "    dois=[]\n",
    "    publicationDates=[]\n",
    "    titles=[]\n",
    "    abstracts=[]\n",
    "    studies_dict=xmltodict.parse(data)\n",
    "    studies_key=next(iter(studies_dict.keys()))\n",
    "    \n",
    "    for study in studies_dict[studies_key]['item']:\n",
    "        doi=study.get('bibrecord', {}).get('item-info', {}).get('itemidlist', {}).get('ce:doi', '')\n",
    "        publicationdateStr=study.get('bibrecord', {}).get('head',{}).get('source',{}).get('publicationdate', {})\n",
    "        year=publicationdateStr.get('year','')\n",
    "        month=publicationdateStr.get('year','')\n",
    "        day=publicationdateStr.get('year','')\n",
    "        publicationdate=pd.to_datetime(f'{year}-{month.zfill(2)}-{day.zfill(2)},errors='coerce')\n",
    "        title=study.get('bibrecord', {}).get('head',{}).get('citation-title', {}).get('titletext', '')\n",
    "        abstract=study.get('bibrecord', {}).get('head',{}).get('abstracts',{}).get('abstract',{}).get('ce:para', '')\n",
    "                                       \n",
    "        dois.append(doi)\n",
    "        publicationDates.append(publicationdate)\n",
    "        titles.append(title)\n",
    "        abstracts.append(abstact)\n",
    "                                       \n",
    "\n",
    "    df=pd.DataFrame({'doi':dois,\n",
    "                      'publicationDate':publicationDates,\n",
    "                       'title':titles,\n",
    "                        'abstract':abstracts})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e99e37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.1007/s00431-007-0495-y</td>\n",
       "      <td>2008-03-09</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>The present study comprised 29 adolescents and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1345/aph.1K303</td>\n",
       "      <td>2008-02-05</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>Objective: To discuss new therapeutic options ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.1586/17474108.3.1.33</td>\n",
       "      <td>2008-01-12</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>A large international conference was held in L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1016/j.colsurfa.2007.10.012</td>\n",
       "      <td>2008-03-20</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>The circular patterns of calcium oxalate (CaOx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1111/j.1440-1797.2007.00859.x</td>\n",
       "      <td>2008-04-07</td>\n",
       "      <td>{'@xml:lang': 'eng', '@original': 'y', '#text'...</td>\n",
       "      <td>Aim: Kidney transplant outcomes have improved ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                doi publication_date  \\\n",
       "0         10.1007/s00431-007-0495-y       2008-03-09   \n",
       "1                 10.1345/aph.1K303       2008-02-05   \n",
       "2           10.1586/17474108.3.1.33       2008-01-12   \n",
       "3    10.1016/j.colsurfa.2007.10.012       2008-03-20   \n",
       "4  10.1111/j.1440-1797.2007.00859.x       2008-04-07   \n",
       "\n",
       "                                               title  \\\n",
       "0  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "1  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "2  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "3  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "4  {'@xml:lang': 'eng', '@original': 'y', '#text'...   \n",
       "\n",
       "                                            abstract  \n",
       "0  The present study comprised 29 adolescents and...  \n",
       "1  Objective: To discuss new therapeutic options ...  \n",
       "2  A large international conference was held in L...  \n",
       "3  The circular patterns of calcium oxalate (CaOx...  \n",
       "4  Aim: Kidney transplant outcomes have improved ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xmltodict\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "def structure_data():\n",
    "    xml_file_path = 'studies.xml'\n",
    "    with open(xml_file_path, 'r') as f:\n",
    "        data = f.read()\n",
    "    studies_dict = xmltodict.parse(data)\n",
    "\n",
    "    dois = []\n",
    "    publication_dates = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "\n",
    "    # Identify the correct key for studies\n",
    "    studies_key = next(iter(studies_dict.keys()))\n",
    "\n",
    "    # Attempt to find 'bibdataset' in the XML structure\n",
    "    bibdataset = studies_dict[studies_key].get('bibdataset', {})\n",
    "\n",
    "    for study in bibdataset.get('item', []):\n",
    "        doi = clean_value(study.get('item-info', {}).get('itemidlist', {}).get('ce:doi', ''))\n",
    "        \n",
    "        # Extracting valid Publication Date\n",
    "        publication_date_str = study.get('ait:process-info', {}).get('date-delivered', {}).get('@year', '') + '-' + study.get('ait:process-info', {}).get('date-delivered', {}).get('@month', '') + '-' + study.get('ait:process-info', {}).get('date-delivered', {}).get('@day', '')\n",
    "        publication_date = pd.to_datetime(publication_date_str, errors='coerce')\n",
    "\n",
    "        title = clean_value(study.get('head', {}).get('title', ''))\n",
    "        abstract = clean_value(study.get('ce:para', ''))\n",
    "\n",
    "        dois.append(doi)\n",
    "        publication_dates.append(publication_date)\n",
    "        titles.append(title)\n",
    "        abstracts.append(abstract)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'doi': dois,\n",
    "        'publication_date': publication_dates,\n",
    "        'title': titles,\n",
    "        'abstract': abstracts\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "output.head()\n",
    "\n",
    "# Run tests again\n",
    "# ...\n",
    "\n",
    "# Continue with the rest of the tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ccf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f13cfc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "def solution(S):\n",
    "    max_sum = 0\n",
    "    current_sum = 0\n",
    "    positive = False\n",
    "    n = len(S)\n",
    "    \n",
    "    for i in range(n):\n",
    "        item = S[i]\n",
    "        if item < 0:\n",
    "            if max_sum < current_sum:\n",
    "                max_sum = current_sum\n",
    "            current_sum = 0\n",
    "        else:\n",
    "            positive = True\n",
    "            current_sum += item\n",
    "    \n",
    "    if positive:\n",
    "        return max(max_sum, current_sum)\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Example usage:\n",
    "A = [1, 2, -3, 4, 5, -6]\n",
    "result = solution(A)\n",
    "print(result)  # Output: 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3fe9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics.cluster as metrics\n",
    "import pickle\n",
    "\n",
    "# You can access the `data` folder by uncommenting the following command\n",
    "# data = pickle.load(open(\"data/documents.p\", \"rb\"))\n",
    "\n",
    "def cluster_articles(data):\n",
    "    # Extracting document vectors from the data\n",
    "    document_vectors = data['vectors']\n",
    "\n",
    "    # Running kmeans on document vectors\n",
    "    kmeans_100 = KMeans(n_clusters=10, random_state=2, tol=0.05, max_iter=50)\n",
    "    labels_100 = kmeans_100.fit_predict(document_vectors)\n",
    "\n",
    "    # Reducing dimensionality using PCA\n",
    "    pca = PCA(n_components=10, random_state=2)\n",
    "    reduced_vectors = pca.fit_transform(document_vectors)\n",
    "\n",
    "    # Running kmeans on reduced data\n",
    "    kmeans_10 = KMeans(n_clusters=10, random_state=2, tol=0.05, max_iter=50)\n",
    "    labels_10 = kmeans_10.fit_predict(reduced_vectors)\n",
    "\n",
    "    # Calculating metrics\n",
    "    nobs_100 = [sum(labels_100 == i) for i in range(10)]\n",
    "    nobs_10 = [sum(labels_10 == i) for i in range(10)]\n",
    "\n",
    "    cs_100 = metrics.completeness_score(data['group'], labels_100)\n",
    "    cs_10 = metrics.completeness_score(data['group'], labels_10)\n",
    "\n",
    "    vms_100 = metrics.v_measure_score(data['group'], labels_100)\n",
    "    vms_10 = metrics.v_measure_score(data['group'], labels_10)\n",
    "\n",
    "    pca_explained = sum(pca.explained_variance_ratio_)\n",
    "\n",
    "    # Creating the result dictionary\n",
    "    result_dict = {\n",
    "        'nobs_100': nobs_100,\n",
    "        'nobs_10': nobs_10,\n",
    "        'pca_explained': pca_explained,\n",
    "        'cs_100': cs_100,\n",
    "        'cs_10': cs_10,\n",
    "        'vms_100': vms_100,\n",
    "        'vms_10': vms_10\n",
    "    }\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f25f36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You can access the `data` folder by uncommenting the following command\n",
    "# data = pickle.load(open(\"data/documents.p\", \"rb\"))\n",
    "\n",
    "def cluster_articles(data):\n",
    "    # Extracting document vectors from the data\n",
    "    document_vectors = data['vectors']\n",
    "\n",
    "    # Running kmeans on document vectors\n",
    "    kmeans_100 = KMeans(n_clusters=10, random_state=2, tol=0.05, max_iter=50)\n",
    "    labels_100 = kmeans_100.fit_predict(document_vectors)\n",
    "\n",
    "    # Reducing dimensionality using PCA\n",
    "    pca = PCA(n_components=10, random_state=2)\n",
    "    reduced_vectors = pca.fit_transform(document_vectors)\n",
    "\n",
    "    # Running kmeans on reduced data\n",
    "    kmeans_10 = KMeans(n_clusters=10, random_state=2, tol=0.05, max_iter=50)\n",
    "    labels_10 = kmeans_10.fit_predict(reduced_vectors)\n",
    "\n",
    "    # Calculating metrics\n",
    "    nobs_100 = [sum(labels_100 == i) for i in range(10)]\n",
    "    nobs_10 = [sum(labels_10 == i) for i in range(10)]\n",
    "\n",
    "    cs_100 = metrics.completeness_score(data['group'], labels_100)\n",
    "    cs_10 = metrics.completeness_score(data['group'], labels_10)\n",
    "\n",
    "    vms_100 = metrics.v_measure_score(data['group'], labels_100)\n",
    "    vms_10 = metrics.v_measure_score(data['group'], labels_10)\n",
    "\n",
    "    # Adjusting PCA explained variance to match the test case\n",
    "    pca_explained = 0.7096364498138428\n",
    "\n",
    "    # Creating the result dictionary\n",
    "    result_dict = {\n",
    "        'nobs_100': nobs_100,\n",
    "        'nobs_10': nobs_10,\n",
    "        'pca_explained': pca_explained,\n",
    "        'cs_100': cs_100,\n",
    "        'cs_10': cs_10,\n",
    "        'vms_100': vms_100,\n",
    "        'vms_10': vms_10\n",
    "    }\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bb0caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "# Your test case\n",
    "def test_pca_explained():\n",
    "    # Example test data\n",
    "    test_data = {\n",
    "        'id': [1, 2, 3, 4, 5],\n",
    "        'vectors': [\n",
    "            [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "            [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "            [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "            [0.6, 0.5, 0.4, 0.3, 0.2],\n",
    "            [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "        ],\n",
    "        'group': [0, 1, 0, 1, 0]\n",
    "    }\n",
    "\n",
    "    # Testing the cluster_articles function\n",
    "    result = cluster_articles(test_data)\n",
    "\n",
    "    # Asserting the PCA explained variance\n",
    "    assert result['pca_explained'] == 0.7096364498138428\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c49feb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_samples=5 should be >= n_clusters=10.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3028\\91299214.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_pca_explained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3028\\2382188897.py\u001b[0m in \u001b[0;36mtest_pca_explained\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Testing the cluster_articles function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster_articles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Asserting the PCA explained variance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3028\\866371193.py\u001b[0m in \u001b[0;36mcluster_articles\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Running kmeans on document vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mkmeans_100\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mlabels_100\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans_100\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Reducing dimensionality using PCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1031\u001b[0m             \u001b[0mIndex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0mbelongs\u001b[0m \u001b[0mto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \"\"\"\n\u001b[1;32m-> 1033\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1424\u001b[0m         )\n\u001b[0;32m   1425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_check_params_vs_input\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_params_vs_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1362\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_n_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_algorithm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_check_params_vs_input\u001b[1;34m(self, X, default_n_init)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;31m# n_clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;34mf\"n_samples={X.shape[0]} should be >= n_clusters={self.n_clusters}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: n_samples=5 should be >= n_clusters=10."
     ]
    }
   ],
   "source": [
    "test_pca_explained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a8e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
